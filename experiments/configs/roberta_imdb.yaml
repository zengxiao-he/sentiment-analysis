model:
  type: "roberta"
  num_classes: 2
  dropout_rate: 0.3

data:
  dataset: "imdb"
  tokenizer: "roberta-base"
  max_length: 512

training:
  batch_size: 8  # Smaller batch size for RoBERTa
  learning_rate: 1e-5
  weight_decay: 0.01
  epochs: 5
  patience: 3
  min_delta: 0.001
  checkpoint_dir: "./checkpoints/roberta_imdb"
  results_dir: "./results/roberta_imdb"

logging:
  use_wandb: false
  project_name: "cs224n-sentiment-analysis"
  log_interval: 50 